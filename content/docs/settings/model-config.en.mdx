---
title: Model Configuration
description: NoteGen integrates mainstream AI model services and also supports custom configuration to meet different needs.
icon: Brain
---

![image.png](https://s2.loli.net/2025/07/10/twNG14nsJZvPW6r.png)

## Create Model Configuration

Click the `Create New Configuration` button to open custom and mainstream model provider templates for selection:

![image.png](https://s2.loli.net/2025/07/10/2J9jTLGeSO5HPhw.png)

Note that each configuration corresponds to only one model. Under the same provider, you can click the copy button to quickly create new configurations.

## Configuration

### Custom Name

Used to distinguish different model configurations, can be filled in arbitrarily and can be duplicated.

### BaseURL

Note that you only need to configure up to the **version number**, for example: https://api.openai.com/v1. The suffix will be added automatically. This applies to other vendors as well. Please do not include `chat/completions`, `/embeddings`, etc.

### API Key

Fill in your corresponding key here. For Ollama, LM Studio, etc., you can fill in anything.

### Model

Generally, after BaseURL and API Key are configured correctly, Model will be automatically retrieved and presented as a dropdown list. If it cannot be retrieved, you can fill it in manually.

### Model Type

Select the model type to distinguish different models. Selecting the wrong model type may cause it to not work properly.

Currently supported: Conversation, ~~Image Generation~~, ~~Video~~, ~~Speech~~, Embedding, Reranking.

- Conversation: The most commonly used model type for conversations, writing, and other scenarios.
- Embedding and reranking models: Suitable for knowledge base usage scenarios.
- Other model types will be gradually supported in future versions.

### Advanced Configuration

If you don't understand these configurations, you can ignore them and use the default values.

#### Temperature

What sampling temperature to use, between 0 and 2. Higher values (like 0.8) will make the output more random, while lower values (like 0.2) will make it more focused and deterministic. We generally recommend altering this or top_p but not both.

#### Top P

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.
